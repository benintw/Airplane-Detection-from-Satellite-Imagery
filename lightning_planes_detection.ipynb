{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Friday May 31 - DONE\"\"\"\n",
    "\n",
    "# [done] change: maybe take 36 samples or more samples\n",
    "# [done] change: model restructure\n",
    "\n",
    "\n",
    "\"\"\"Sat June 1st\"\"\"\n",
    "# [solved] warning: GradCAM behavior is weird, look at the heatmap and truth vs. predicted\n",
    "# - solve by: build deeper model, use last layer of convo. for gradCAM\n",
    "# - cuz in the current 2 layer convo , the last convo might not see a lot\n",
    "# [done] Do Data augmentation\n",
    "\n",
    "\n",
    "# [done ]Restructure dataset and get_dataloader so that we can get train_dataloader(with transform and augmentation),\n",
    "# - val_dataloader with transform only,\n",
    "# - test_dataloader with transform only\n",
    "## But we really just need to have train_dataloader that has augmentation because the only transform we'll use\n",
    "## is ToTensor() which converts to [0, 1] which slows down training and leads to worse results\n",
    "\n",
    "\"\"\"Sun June 2st\"\"\"\n",
    "# [] Make the model_v1 more complex\n",
    "\n",
    "# [not gonna do it] restructure the code to different .py\n",
    "# [done] use Lightning\n",
    "# [done] transfer learning -> need to add 'transform' in custom dataset\n",
    "\n",
    "\"\"\"Mon June 3rd\"\"\"\n",
    "# [done] Transfer learning with two or three models\n",
    "# [done] Do Early STopping\n",
    "# [not gonna] lightning confusion matrix\n",
    "# [done] try RichProgressBar\n",
    "\n",
    "# [] train longer\n",
    "# [done] WeightedRandomSampler\n",
    "# [done] functionalize the GradCAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "# from lightning.pytorch.tuner import Tuner\n",
    "from lightning.pytorch.callbacks import ModelSummary\n",
    "from lightning.pytorch.utilities.model_summary import ModelSummary as m_summary\n",
    "\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import RichProgressBar\n",
    "\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import make_grid\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torchinfo import summary\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Additional Libraries\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "from watermark import watermark\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "from pytorch_grad_cam import (\n",
    "    GradCAM,\n",
    "    ScoreCAM,\n",
    "    GradCAMPlusPlus,\n",
    "    AblationCAM,\n",
    "    XGradCAM,\n",
    "    EigenCAM,\n",
    ")\n",
    "from pytorch_grad_cam.utils.image import (\n",
    "    show_cam_on_image,\n",
    "    deprocess_image,\n",
    "    preprocess_image,\n",
    ")\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "\n",
    "import cv2\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Training time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and Visualizing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"planesnet/planesnet\"\n",
    "\n",
    "class_planes = []\n",
    "class_no_planes = []\n",
    "\n",
    "for filename in os.listdir(dirname):\n",
    "\n",
    "    if filename.startswith(\"1\"):\n",
    "        class_planes.append(filename)\n",
    "    elif filename.startswith(\"0\"):\n",
    "        class_no_planes.append(filename)\n",
    "\n",
    "print(len(class_planes), len(class_no_planes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bar chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for the bar chart\n",
    "data = [len(class_planes), len(class_no_planes)]  # Number of images in each class\n",
    "class_labels = [\"Planes\", \"No Planes\"]  # Class labels\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=300)\n",
    "# Create a bar chart with Seaborn\n",
    "ax = sns.barplot(x=class_labels, y=data)\n",
    "\n",
    "# Add data labels on top of bars\n",
    "for bar in ax.containers[0]:\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + 3,\n",
    "        str(int(height)),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=12,\n",
    "    )  # Adjust formatting\n",
    "\n",
    "plt.xlabel(\"Class\", fontsize=12)\n",
    "plt.ylabel(\"Number of Images\", fontsize=12)\n",
    "plt.title(\"Distribution of Images in Planesnet Dataset\", fontsize=15)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.savefig(\"plots/ditribution_of_dataset.png\", dpi=300)\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pie chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [len(class_planes), len(class_no_planes)]\n",
    "class_labels = [\"Planes\", \"No Planes\"]  # Class labels\n",
    "\n",
    "# Calculate total images and percentages\n",
    "total_images = sum(data)\n",
    "percentages = [value / total_images * 100 for value in data]\n",
    "\n",
    "# Create a pie chart with Matplotlib (within Seaborn context)\n",
    "plt.figure(figsize=(8, 8), dpi=300)\n",
    "pie_chart = plt.pie(\n",
    "    x=percentages, labels=class_labels, autopct=\"%1.1f%%\", startangle=140\n",
    ")\n",
    "\n",
    "# Customize the chart title (optional)\n",
    "plt.title(\"Distribution of Images in Planesnet Dataset (Percentage)\", fontsize=15)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"plots/class_distribution_pie.png\", dpi=200, transparent=False)\n",
    "\n",
    "# Optional: Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_df(json_path: str):\n",
    "    df = pd.read_json(json_path)\n",
    "    df.drop(columns=[\"scene_ids\", \"locations\"], inplace=True)\n",
    "\n",
    "    pixel_columns_name = np.empty(1200, dtype=object)\n",
    "    channels = [\"r\", \"g\", \"b\"]\n",
    "    for c in channels:\n",
    "        for p in range(400):\n",
    "            pixel_columns_name[400 * channels.index(c) + p] = c + \"_\" + str(p)\n",
    "\n",
    "    image_data = pd.DataFrame(df[\"data\"].values.tolist(), columns=pixel_columns_name)\n",
    "    labels = df.labels\n",
    "\n",
    "    image_data = pd.concat([image_data, labels], axis=1)\n",
    "\n",
    "    return image_data\n",
    "\n",
    "\n",
    "image_data = get_correct_df(\"planesnet.json\")\n",
    "image_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom dataset: PlanesDatasetJson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanesDatasetJson(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        is_Train: bool,\n",
    "        normalized: bool,\n",
    "        apply_aug: bool,\n",
    "        data_transforms=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = dataframe.copy()\n",
    "        self.is_Train = is_Train\n",
    "        self.normalized = normalized\n",
    "        self.apply_aug = apply_aug\n",
    "        self.data_transforms = data_transforms\n",
    "\n",
    "        self.y = self.df[\"labels\"]\n",
    "        self.X = self.df.drop(\"labels\", inplace=False, axis=1)\n",
    "\n",
    "        self.images = torch.from_numpy(self.X.to_numpy().reshape(-1, 3, 20, 20)).type(\n",
    "            torch.float32\n",
    "        )\n",
    "        self.labels = torch.from_numpy(self.y.to_numpy()).type(torch.float32)\n",
    "\n",
    "        self.augmentation = torchvision.transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size=(20, 20)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomRotation(60),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        images = self.images[idx]\n",
    "\n",
    "        # apply pretrained-model specific transforms here\n",
    "        if self.data_transforms is not None:\n",
    "            images = self.data_transforms(images)\n",
    "\n",
    "        if self.normalized:  # default: False\n",
    "            images = images / 255.0\n",
    "\n",
    "        if self.is_Train and self.apply_aug:\n",
    "            images = self.augmentation(images)\n",
    "\n",
    "        return images, self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN_V1(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=32,\n",
    "                stride=(2, 2),\n",
    "                kernel_size=(3, 3),\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                stride=(2, 2),\n",
    "                kernel_size=(3, 3),\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(0.02),\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=16,\n",
    "                stride=(2, 2),\n",
    "                kernel_size=(3, 3),\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(p=0.02),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16 * 3 * 3, out_features=32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=32, out_features=num_classes),\n",
    "            # nn.Sigmoid(), ## If not using nn.Sigmoid(), then loss=torch.nn.BCEWithLogitsLoss()\n",
    "            ## If using nn.Sigmoid(), then loss = nn.BCELoss(), this loss needs pred be between [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchview import draw_graph\n",
    "\n",
    "model = SimpleCNN_V1(num_classes=2)\n",
    "batch_size = 64\n",
    "model_graph = draw_graph(model, input_size=(1, 3, 20, 20), device=\"meta\")\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "graphviz.set_jupyter_format(\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightningDataModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LightningDataModule\n",
    "\n",
    "\n",
    "class PlanesLightningDataModule(L.LightningDataModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        normalized: bool,\n",
    "        apply_aug: bool,\n",
    "        batch_size: int,\n",
    "        data_transforms=None,\n",
    "        test_size=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = dataframe.copy()\n",
    "        self.normalized = normalized\n",
    "        self.apply_aug = apply_aug\n",
    "        self.batch_size = batch_size\n",
    "        self.data_transforms = data_transforms\n",
    "        self.test_size = test_size\n",
    "\n",
    "        self.augmentation = torchvision.transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size=(20, 20)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomRotation(60),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "\n",
    "        self.shuffled_dataframe = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        df_train_val, self.df_test = train_test_split(\n",
    "            self.shuffled_dataframe, test_size=self.test_size\n",
    "        )\n",
    "        self.df_train, self.df_val = train_test_split(\n",
    "            df_train_val, test_size=self.test_size\n",
    "        )\n",
    "\n",
    "        # calculate sample weights:\n",
    "        train_class_counts = self.df_train[\"labels\"].value_counts()\n",
    "        train_sampling_weights = [\n",
    "            1 / train_class_counts[i] for i in self.df_train.labels.values\n",
    "        ]\n",
    "        self.train_sampler = WeightedRandomSampler(\n",
    "            weights=train_sampling_weights,\n",
    "            num_samples=len(self.df_train),\n",
    "            replacement=True,\n",
    "        )\n",
    "\n",
    "        val_class_counts = self.df_val[\"labels\"].value_counts()\n",
    "        val_sampling_weights = [\n",
    "            1 / val_class_counts[i] for i in self.df_val.labels.values\n",
    "        ]\n",
    "        self.val_sampler = WeightedRandomSampler(\n",
    "            weights=val_sampling_weights, num_samples=len(self.df_val), replacement=True\n",
    "        )\n",
    "\n",
    "        test_class_counts = self.df_test[\"labels\"].value_counts()\n",
    "        test_sampling_weights = [\n",
    "            1 / test_class_counts[i] for i in self.df_test.labels.values\n",
    "        ]\n",
    "        self.test_sampler = WeightedRandomSampler(\n",
    "            weights=test_sampling_weights,\n",
    "            num_samples=len(self.df_test),\n",
    "            replacement=True,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"length of dataloaders:\\n\"\n",
    "            f\"train_dataloader: ({int(len(self.df_train)/self.batch_size)}) | \"\n",
    "            f\"val_dataloader: ({int(len(self.df_val)/self.batch_size)}) | \"\n",
    "            f\"test_dataloader: ({int(len(self.df_test)/self.batch_size)})\"\n",
    "        )\n",
    "\n",
    "    def setup(self, stage: str = None):\n",
    "        self.train_dataset = PlanesDatasetJson(\n",
    "            dataframe=self.df_train,\n",
    "            is_Train=True,\n",
    "            normalized=self.normalized,\n",
    "            apply_aug=self.apply_aug,\n",
    "            data_transforms=self.data_transforms,\n",
    "        )\n",
    "\n",
    "        self.val_dataset = PlanesDatasetJson(\n",
    "            dataframe=self.df_val,\n",
    "            is_Train=False,\n",
    "            normalized=self.normalized,\n",
    "            apply_aug=False,\n",
    "            data_transforms=self.data_transforms,\n",
    "        )\n",
    "        self.test_dataset = PlanesDatasetJson(\n",
    "            dataframe=self.df_test,\n",
    "            is_Train=False,\n",
    "            normalized=self.normalized,\n",
    "            apply_aug=False,\n",
    "            data_transforms=self.data_transforms,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        self.train_dl = DataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            drop_last=True,\n",
    "            sampler=self.train_sampler,\n",
    "        )\n",
    "        return self.train_dl\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        self.val_dl = DataLoader(\n",
    "            dataset=self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            drop_last=False,\n",
    "            sampler=self.val_sampler,\n",
    "        )\n",
    "        return self.val_dl\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        self.test_dl = DataLoader(\n",
    "            dataset=self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            drop_last=False,\n",
    "            sampler=self.test_sampler,\n",
    "        )\n",
    "        return self.test_dl\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        self.predict_dl = DataLoader(\n",
    "            dataset=self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            drop_last=False,\n",
    "            sampler=self.test_sampler,\n",
    "        )\n",
    "        return self.predict_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiement 1: WeightedRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for powerpoint slides\n",
    "\n",
    "dm = PlanesLightningDataModule(\n",
    "    dataframe=image_data,\n",
    "    normalized=True,  # [0, 1]\n",
    "    apply_aug=True,\n",
    "    batch_size=64,\n",
    "    data_transforms=None,\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "\n",
    "full_dataset = PlanesDatasetJson(\n",
    "    dataframe=dm.shuffled_dataframe,\n",
    "    is_Train=True,\n",
    "    normalized=True,\n",
    "    apply_aug=False,\n",
    "    data_transforms=None,\n",
    ")\n",
    "\n",
    "dm_shuffled_df = dm.shuffled_dataframe\n",
    "# class_counts = dm_shuffled_df[\"labels\"].value_counts()\n",
    "# sample_weights = [1 / class_counts[i] for i in dm_shuffled_df.labels.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_shuffled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = dm_shuffled_df[\"labels\"].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = [1 / class_counts[i] for i in dm_shuffled_df.labels.values]\n",
    "sample_weights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_shuffled_df[\"labels\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dm = PlanesLightningDataModule(\n",
    "    dataframe=image_data,\n",
    "    normalized=True,  # [0, 1]\n",
    "    apply_aug=True,\n",
    "    batch_size=64,\n",
    "    data_transforms=None,\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "\n",
    "full_dataset = PlanesDatasetJson(\n",
    "    dataframe=dm.shuffled_dataframe,\n",
    "    is_Train=True,\n",
    "    normalized=True,\n",
    "    apply_aug=False,\n",
    "    data_transforms=None,\n",
    ")\n",
    "\n",
    "\n",
    "dm_shuffled_df = dm.shuffled_dataframe\n",
    "class_counts = dm_shuffled_df[\"labels\"].value_counts()\n",
    "sample_weights = [1 / class_counts[i] for i in dm_shuffled_df.labels.values]\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "### Create dataloader without WeightedRandomSampler ###\n",
    "dataloader_no_sampler = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "### Create dataloader with WeightedRandomSampler ###\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights, num_samples=len(full_dataset), replacement=True\n",
    ")\n",
    "dataloader_with_sampler = DataLoader(\n",
    "    full_dataset, batch_size=batch_size, sampler=sampler\n",
    ")\n",
    "\n",
    "print()\n",
    "print(f\"len of dataset: {len(full_dataset)} | batch_size: {batch_size}\")\n",
    "print(f\"len of dataloader: {len(dataloader_with_sampler)}\")\n",
    "\n",
    "\n",
    "### DONE BELOW ###\n",
    "def visualize_dataloader(\n",
    "    dataloader, balanced: bool, collect_n_batches: int, batch_size: int\n",
    ") -> None:\n",
    "    \"\"\"Visualizes the data ditribution in the dataloader\"\"\"\n",
    "\n",
    "    dataset_type = \"Balanced\" if balanced else \"Imbalanced\"\n",
    "\n",
    "    class_0_batch_counts = []\n",
    "    class_1_batch_counts = []\n",
    "\n",
    "    for i, (_, labels) in enumerate(dataloader):\n",
    "        if i < collect_n_batches:\n",
    "            batch_labels = labels.tolist()\n",
    "            class_0_count = batch_labels.count(0)\n",
    "            class_1_count = batch_labels.count(1)\n",
    "            class_0_batch_counts.append(class_0_count)\n",
    "            class_1_batch_counts.append(class_1_count)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(15, 10), dpi=300)\n",
    "    plt.suptitle(f\"Class Distribution Across Batches\", fontsize=15)\n",
    "\n",
    "    ind = np.arange(len(class_0_batch_counts))\n",
    "    width = 0.35\n",
    "\n",
    "    ax.bar(ind, class_0_batch_counts, width, label=\"0: No Planes\")\n",
    "    ax.bar(ind + width, class_1_batch_counts, width, label=\"1: Planes\")\n",
    "    ax.set_xticks(ind, ind + 1)\n",
    "    ax.set_xlabel(\"Batch index\", fontsize=12)\n",
    "    ax.set_ylabel(\"No. of images in batch\", fontsize=12)\n",
    "    ax.yaxis.set_major_locator(\n",
    "        MaxNLocator(integer=True)\n",
    "    )  # Set integer ticks for y-axis\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    plt.legend()\n",
    "    ax.grid(color=\"lightgray\", linestyle=\"-\", linewidth=0.5, alpha=0.7)\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "    plt.title(f\"({dataset_type} Dataset) | Batch size: {batch_size}\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"balanced_imbalanced_dataset_plots/{dataset_type}.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_dataloader(\n",
    "    dataloader_no_sampler, balanced=False, collect_n_batches=40, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataloader(\n",
    "    dataloader_with_sampler,\n",
    "    balanced=True,\n",
    "    collect_n_batches=40,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "L.seed_everything(RANDOM_SEED)\n",
    "\n",
    "dm = PlanesLightningDataModule(\n",
    "    dataframe=image_data,\n",
    "    normalized=True,  # [0, 1]\n",
    "    apply_aug=True,\n",
    "    batch_size=64,\n",
    "    data_transforms=None,\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in dm.train_dataloader():\n",
    "    break\n",
    "\n",
    "# print(f\"images[0] values:\\n{images[61]}\")\n",
    "print(f\"max and min of images[0]: {images[61].max()}, {images[61].min()}\")\n",
    "print(f\"images shape: {images.shape}\")\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=300)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(\n",
    "    torchvision.utils.make_grid(images[:64], padding=2, normalize=True).permute(1, 2, 0)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in dm.test_dataloader():\n",
    "    break\n",
    "\n",
    "print(f\"images shape: {images.shape}\")\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=300)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Testing Images\")\n",
    "plt.imshow(\n",
    "    torchvision.utils.make_grid(images[:64], padding=1, normalize=True).permute(1, 2, 0)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightningModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LightningModule\n",
    "class PlanesLightningModule(L.LightningModule):\n",
    "    def __init__(self, model: torch.nn.Module, learning_rate: float, input_size):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.input_size = input_size\n",
    "        self.example_input_array = torch.rand((1, 3, self.input_size, self.input_size))\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "\n",
    "        ### For plotting purposes\n",
    "        self.train_loss_list = []\n",
    "        self.val_loss_list = []\n",
    "        self.test_loss_list = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _shared_step(self, batch):\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        return loss, labels, predicted_labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, labels, predicted_labels = self._shared_step(batch)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True\n",
    "        )\n",
    "        self.train_loss_list.append(loss.item())  # Append loss for plotting\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, labels, predicted_labels = self._shared_step(batch)\n",
    "        self.log(\n",
    "            \"val_loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True\n",
    "        )\n",
    "        self.val_loss_list.append(loss.item())\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, labels, predicted_labels = self._shared_step(batch)\n",
    "        self.log(\n",
    "            \"test_loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True\n",
    "        )\n",
    "        self.test_loss_list.append(loss.item())\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        return predictions\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def plot_metrics(self):\n",
    "\n",
    "        averaging_iterations = 100\n",
    "        # Ensure data on CPU before plotting\n",
    "        cpu_train_loss = self.train_loss_list\n",
    "        cpu_val_loss = self.val_loss_list\n",
    "        cpu_test_loss = self.test_loss_list\n",
    "        # cpu_train_acc = [acc.cpu().item() for acc in self.train_acc_list]\n",
    "\n",
    "        # Plot Loss\n",
    "        model_details = (\n",
    "            f\"model: {self.model.__class__.__name__}, lr: {self.learning_rate}\"\n",
    "        )\n",
    "        main_title = \"Training vs Validation Loss per mini-batches\"\n",
    "\n",
    "        plt.figure(figsize=(15, 8))\n",
    "\n",
    "        ### new\n",
    "        ax1 = plt.subplot(1, 1, 1)\n",
    "        ax1.plot(cpu_train_loss, label=\"Training Loss\")\n",
    "        ax1.plot(cpu_val_loss, label=\"Validation Loss\", linestyle=\"--\")\n",
    "        plt.xlabel(\"Num of mini-batches\", fontsize=12)\n",
    "        plt.ylabel(\"Loss\", fontsize=12)\n",
    "        plt.suptitle(main_title, fontsize=15)\n",
    "        plt.title(model_details, fontsize=12)\n",
    "\n",
    "        # plot running avg\n",
    "        kernel = np.ones(averaging_iterations) / averaging_iterations\n",
    "        smoothed_train_loss = np.convolve(cpu_train_loss, kernel, mode=\"valid\")\n",
    "        smoothed_val_loss = np.convolve(cpu_val_loss, kernel, mode=\"valid\")\n",
    "\n",
    "        ax1.plot(smoothed_train_loss, label=\"Running Average Training loss\")\n",
    "        ax1.plot(smoothed_val_loss, label=\"Running Average Validation loss\")\n",
    "\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"plots/minibatch_train_val_loss_lightning\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    def on_train_end(self):\n",
    "        self.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "INPUT_SIZE = 20\n",
    "\n",
    "pytorch_model = SimpleCNN_V1(num_classes=2)\n",
    "lightning_model = PlanesLightningModule(\n",
    "    pytorch_model, learning_rate=0.05, input_size=INPUT_SIZE\n",
    ")\n",
    "summary = m_summary(lightning_model, max_depth=-1)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(watermark(packages=\"torch, lightning\", python=True))\n",
    "print(device)\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "IMG_SIZE = 20\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "NUM_EPOCHS = 46\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "L.seed_everything(RANDOM_SEED)\n",
    "\n",
    "datamodule = PlanesLightningDataModule(\n",
    "    dataframe=image_data,\n",
    "    normalized=True,  # [0, 1]\n",
    "    apply_aug=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    data_transforms=None,\n",
    "    test_size=TEST_SIZE,\n",
    ")\n",
    "\n",
    "pytorch_model = SimpleCNN_V1(num_classes=2)\n",
    "lightning_model = PlanesLightningModule(\n",
    "    pytorch_model, learning_rate=LEARNING_RATE, input_size=IMG_SIZE\n",
    ")  # lr is key\n",
    "\n",
    "callbacks = [\n",
    "    TQDMProgressBar(refresh_rate=20),\n",
    "    ModelSummary(max_depth=3),\n",
    "    # RichProgressBar(leave=True),\n",
    "    # EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5),\n",
    "]\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    # fast_dev_run=2,\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    accelerator=\"mps\",\n",
    "    devices=\"auto\",\n",
    "    logger=CSVLogger(save_dir=\"logs\", name=\"my_lightning_model\"),\n",
    "    precision=\"16-mixed\",\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "train_time_start = timer()\n",
    "trainer.fit(\n",
    "    model=lightning_model,\n",
    "    # train_dataloaders=None,\n",
    "    # val_dataloaders=None,\n",
    "    datamodule=datamodule,\n",
    ")\n",
    "train_time_end = timer()\n",
    "total_train_time_model_0 = print_train_time(\n",
    "    start=train_time_start,\n",
    "    end=train_time_end,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = trainer.logger.log_dir\n",
    "# metrics = pd.read_csv(f\"{log_dir}/metrics.csv\")\n",
    "# metrics.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = trainer.logger.log_dir\n",
    "# metrics = pd.read_csv(f\"{log_dir}/metrics.csv\")\n",
    "# # Group metrics by epoch and calculate mean for each metric\n",
    "# df_metrics = metrics.groupby(\"epoch\").mean()\n",
    "\n",
    "# # Add epoch as a column\n",
    "# df_metrics[\"epoch\"] = df_metrics.index  # Index is the grouping key (epoch)\n",
    "# print(df_metrics)\n",
    "\n",
    "# df_metrics[[\"train_loss_epoch\", \"val_loss_epoch\"]].iloc[-1, :].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_acc(log_dir) -> None:\n",
    "\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = [10, 8]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "    metrics = pd.read_csv(f\"{log_dir}/metrics.csv\")\n",
    "    # Group metrics by epoch and calculate mean for each metric\n",
    "    df_metrics = metrics.groupby(\"epoch\").mean()\n",
    "\n",
    "    num_epochs = len(df_metrics)\n",
    "\n",
    "    # Add epoch as a column\n",
    "    df_metrics[\"epoch\"] = df_metrics.index  # Index is the grouping key (epoch)\n",
    "\n",
    "    print(df_metrics.head(10))\n",
    "\n",
    "    last_train_epoch_loss = (\n",
    "        df_metrics[[\"train_loss_epoch\", \"val_loss_epoch\"]].iloc[-1, :].iloc[0]\n",
    "    )\n",
    "    last_val_epoch_loss = (\n",
    "        df_metrics[[\"train_loss_epoch\", \"val_loss_epoch\"]].iloc[-1, :].iloc[-1]\n",
    "    )\n",
    "\n",
    "    df_metrics[[\"train_loss_epoch\", \"val_loss_epoch\"]].plot(\n",
    "        grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"Loss\"\n",
    "    )\n",
    "\n",
    "    plt.suptitle(\"Training and Validation Loss per Epoch\", fontsize=15)\n",
    "    plt.title(\n",
    "        f\"{num_epochs}/{NUM_EPOCHS} Epochs | Batch Size: {BATCH_SIZE} | LR: {LEARNING_RATE}\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "\n",
    "    plt.scatter(\n",
    "        len(df_metrics[[\"train_loss_epoch\", \"val_loss_epoch\"]]) - 1,\n",
    "        last_train_epoch_loss,\n",
    "        marker=\"o\",\n",
    "        c=\"red\",\n",
    "        alpha=0.8,\n",
    "        label=f\"Last Training Epoch Loss: {last_train_epoch_loss:.4f}\",\n",
    "    )\n",
    "\n",
    "    plt.scatter(\n",
    "        len(df_metrics[[\"train_loss_epoch\", \"val_loss_epoch\"]]) - 1,\n",
    "        last_val_epoch_loss,\n",
    "        marker=\"o\",\n",
    "        c=\"green\",\n",
    "        alpha=0.8,\n",
    "        label=f\"Last Validation Epoch Loss: {last_val_epoch_loss:.4f}\",\n",
    "    )\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f\"{log_dir}/loss_curve.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RANDOM_SEED = 123\n",
    "IMG_SIZE = 20\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "NUM_EPOCHS = 47 #0.0465\n",
    "LEARNING_RATE = 0.05\n",
    "\"\"\"\n",
    "\n",
    "plot_loss_and_acc(trainer.logger.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RANDOM_SEED = 123\n",
    "IMG_SIZE = 20\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "NUM_EPOCHS = 100 # 0.0468\n",
    "LEARNING_RATE = 0.05\n",
    "\"\"\"\n",
    "\n",
    "plot_loss_and_acc(trainer.logger.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RANDOM_SEED = 123\n",
    "IMG_SIZE = 20\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "NUM_EPOCHS = 41\n",
    "LEARNING_RATE = 0.05\n",
    "\"\"\"\n",
    "\n",
    "plot_loss_and_acc(trainer.logger.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RANDOM_SEED = 123\n",
    "IMG_SIZE = 20\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "NUM_EPOCHS = 46 #0.0580\n",
    "LEARNING_RATE = 0.05\n",
    "\"\"\"\n",
    "\n",
    "plot_loss_and_acc(trainer.logger.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RANDOM_SEED = 123\n",
    "IMG_SIZE = 20\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "NUM_EPOCHS = 50 # 0.0693\n",
    "LEARNING_RATE = 0.05\n",
    "\"\"\"\n",
    "\n",
    "plot_loss_and_acc(trainer.logger.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RANDOM_SEED = 123\n",
    "IMG_SIZE = 20\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "NUM_EPOCHS = 50 # 0.0693\n",
    "LEARNING_RATE = 0.05\n",
    "\"\"\"\n",
    "\n",
    "plot_loss_and_acc(trainer.logger.log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.test(model=lightning_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaiveModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_naive_model(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "):\n",
    "\n",
    "    y_true_labels = []\n",
    "    naive_predictions = []\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        all_zeros = torch.zeros_like(labels)\n",
    "        y_true_labels.extend(labels.cpu().numpy())\n",
    "        naive_predictions.extend(all_zeros.numpy())\n",
    "\n",
    "    ### classification_report\n",
    "    target_names = [\"No Plane\", \"Plane\"]\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_true=y_true_labels,\n",
    "            y_pred=naive_predictions,\n",
    "            target_names=target_names,\n",
    "            zero_division=0.0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    cm = confusion_matrix(y_true=y_true_labels, y_pred=naive_predictions)\n",
    "    ConfusionMatrixDisplay(cm).plot(cmap=\"viridis\").ax_.set_title(\n",
    "        \"NaiveModel: Confusion Matrix\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "evaluate_naive_model(dataloader=datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the trained-model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_the_lightning_model(\n",
    "    lightning_model: L.LightningModule,\n",
    "    datamodule: L.LightningDataModule,\n",
    "):\n",
    "\n",
    "    lightning_model.eval()\n",
    "    total_test_loss = 0\n",
    "    test_loss_per_batch = []\n",
    "    y_true_labels = []\n",
    "    y_predictions = []\n",
    "\n",
    "    model_name = lightning_model.model.__class__.__name__\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        dataloader = datamodule.test_dataloader()\n",
    "        for images, labels in dataloader:\n",
    "            # images, labels = images.to(device), labels.to(device)\n",
    "            test_logits = lightning_model(images)\n",
    "            test_minibatch_loss = F.cross_entropy(\n",
    "                test_logits, labels.type(torch.LongTensor)\n",
    "            )\n",
    "            test_loss_per_batch.append(test_minibatch_loss.item())\n",
    "            total_test_loss += test_minibatch_loss.item()\n",
    "\n",
    "            # Store labels and predictions for metric calculations\n",
    "            y_true_labels.extend(labels.cpu().numpy())\n",
    "            y_predictions.extend(test_logits.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(dataloader)\n",
    "        print(f\"Average test loss: {avg_test_loss:5f}\\n\")\n",
    "\n",
    "        ### classification_report\n",
    "        target_names = [\"No Plane\", \"Plane\"]\n",
    "\n",
    "        report = classification_report(\n",
    "            y_true=y_true_labels, y_pred=y_predictions, target_names=target_names\n",
    "        )\n",
    "        with open(\n",
    "            f\"classification_reports/{model_name}_classification_report.txt\", \"w\"\n",
    "        ) as f:\n",
    "            f.write(report)\n",
    "\n",
    "        print(report)\n",
    "\n",
    "    return avg_test_loss, test_loss_per_batch, y_true_labels, y_predictions\n",
    "\n",
    "\n",
    "avg_test_loss, test_loss_per_batch, y_true_labels, y_predictions = (\n",
    "    evaluate_the_lightning_model(\n",
    "        lightning_model=lightning_model,\n",
    "        datamodule=datamodule,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_preds = []\n",
    "incorrect_preds = []\n",
    "\n",
    "\n",
    "type(y_true_labels)\n",
    "print(y_true_labels[0] == y_predictions[0])\n",
    "\n",
    "for i in range(len(y_true_labels)):\n",
    "    if y_predictions[i] == y_true_labels[i]:\n",
    "        correct_preds.append(i)\n",
    "    else:\n",
    "        incorrect_preds.append(i)\n",
    "\n",
    "print(f\"Correct predictions: {len(correct_preds)}\")\n",
    "print(f\"Incorrect predictions: {len(incorrect_preds)}\")\n",
    "print(\n",
    "    f\"accuracy: {len(correct_preds)/(len(correct_preds) + len(incorrect_preds)) * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(y_true, y_pred) -> None:\n",
    "\n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    ConfusionMatrixDisplay(cm).plot(cmap=\"viridis\").ax_.set_title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "get_confusion_matrix(y_true=y_true_labels, y_pred=y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `plot_test_loss_per_batch()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_loss_per_batch(\n",
    "    test_loss_per_batch: list,\n",
    "    batch_size,\n",
    "    lr,\n",
    "    num_epochs,\n",
    "):\n",
    "\n",
    "    title = f\"Testing loss per batch\\n batch_size:{batch_size}, lr:{lr}\"\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(test_loss_per_batch, label=\"Testing loss\")\n",
    "\n",
    "    last_batch_loss = test_loss_per_batch[-1]\n",
    "    plt.scatter(\n",
    "        len(test_loss_per_batch) - 1,\n",
    "        last_batch_loss,\n",
    "        marker=\"o\",\n",
    "        c=\"red\",\n",
    "        alpha=0.8,\n",
    "        label=f\"Last minibatch loss: {last_batch_loss:.4f}\",\n",
    "    )\n",
    "\n",
    "    plt.xlabel(f\"Num of mini-batches (Total: {len(test_loss_per_batch)})\")\n",
    "    plt.ylabel(f\"Loss\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\n",
    "        f\"plots/epoch_test_loss_{batch_size}_{num_epochs}_{lr}.png\",\n",
    "        transparent=False,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_test_loss_per_batch(\n",
    "    test_loss_per_batch, batch_size=BATCH_SIZE, lr=LEARNING_RATE, num_epochs=NUM_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions and plot them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed_value=42):\n",
    "    \"\"\"Sets the random seed for reproducibility\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "\n",
    "\n",
    "def collect_samples_to_predict(\n",
    "    datamodule: L.LightningDataModule, num_samples=36\n",
    ") -> tuple[list, torch.Tensor]:\n",
    "    \"\"\"Collects a specified number of random samples and labels from the DataLoader.\n",
    "\n",
    "    Args:\n",
    "        dataloader (torch.utils.data.DataLoader): The dataloader to collect samples from.\n",
    "        num_samples (int, optional): The desired number of samples to collect. Defaults to 36.\n",
    "\n",
    "    Returns:\n",
    "        tuple[list, torch.Tensor]: A tuple containing a list of collected samples and a tensor of corresponding ground truth labels.\n",
    "    \"\"\"\n",
    "\n",
    "    test_samples = []\n",
    "    test_labels = []\n",
    "    dataloader = datamodule.test_dataloader()\n",
    "\n",
    "    for samples, labels in dataloader:\n",
    "        # select 16  # change: maybe take 36 samples or more samples\n",
    "        if len(test_samples) >= num_samples:\n",
    "            break\n",
    "\n",
    "        # generate a random index\n",
    "        n = random.randint(0, samples.shape[0] - 1)\n",
    "        test_samples.append(samples[n])  # 1 observation\n",
    "        test_labels.append(labels[n])  # 1 observation\n",
    "\n",
    "        ground_truth = torch.tensor(test_labels)\n",
    "\n",
    "    return test_samples, ground_truth\n",
    "\n",
    "\n",
    "def make_predictions(\n",
    "    lightning_model: L.LightningModule, test_samples: list\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Makes predictions on a list of samples using the model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to use for predictions.\n",
    "        test_samples (list): A list of samples to make predictions on.\n",
    "        device (torch.device): The device to use for computations (e.g., CPU or GPU).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor containing the predicted labels for the samples.\n",
    "    \"\"\"\n",
    "\n",
    "    pred_labels_list = []\n",
    "\n",
    "    lightning_model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for sample in test_samples:\n",
    "            pred_logits = lightning_model(sample.unsqueeze(dim=0))\n",
    "            # y_probs = torch.softmax(y_logits, dim=1)\n",
    "            pred_labels = torch.softmax(pred_logits, dim=1).argmax(dim=1)\n",
    "            pred_labels_list.append(pred_labels.float().cpu())\n",
    "            predictions = torch.stack(pred_labels_list)\n",
    "\n",
    "    return predictions.squeeze()\n",
    "\n",
    "\n",
    "def plotting(test_samples, predictions, ground_truth, model, normalized=True) -> None:\n",
    "    \"\"\"Creates a plot visualizing predictions vs. ground truth labels.\n",
    "\n",
    "    Args:\n",
    "        test_samples (list): A list of test samples (images).\n",
    "        predictions (torch.Tensor): A tensor containing the predicted labels.\n",
    "        ground_truth (torch.Tensor): A tensor containing the ground truth labels.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    plt.figure(figsize=(13, 13), dpi=300)\n",
    "\n",
    "    nrows, ncols = 6, 6\n",
    "\n",
    "    for i, sample in enumerate(test_samples):\n",
    "\n",
    "        plt.subplot(nrows, ncols, i + 1)\n",
    "        if normalized:  # default: True\n",
    "            plt.imshow((sample).permute(1, 2, 0))\n",
    "        else:\n",
    "            plt.imshow((sample / 255.0).permute(1, 2, 0))\n",
    "\n",
    "        pred_label = \"Plane\" if predictions[i] == 1.0 else \"No Plane\"\n",
    "        truth_label = \"Plane\" if ground_truth[i] == 1.0 else \"No Plane\"\n",
    "\n",
    "        if pred_label == truth_label:\n",
    "            truth_label = \"*Plane*\" if truth_label == \"Plane\" else \"No Plane\"\n",
    "            title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
    "            plt.title(title_text, fontsize=8, c=\"g\")  # green text if correct\n",
    "        else:\n",
    "            truth_label = \"*Plane*\" if truth_label == \"Plane\" else \"No Plane\"\n",
    "            title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
    "            plt.title(title_text, fontsize=8, c=\"r\")  # red text if incorrect\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Predictions vs. Truths\", fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"pred_vs_truth_plots/{model_name}.png\", transparent=False, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_pred_vs_truth(\n",
    "    datamodule: L.LightningDataModule,\n",
    "    lightning_model: L.LightningModule,\n",
    "    num_samples: int = 36,\n",
    "    set_random: bool = True,\n",
    "    normalized: bool = True,\n",
    "):\n",
    "    \"\"\"Plots predictions vs. true labels\"\"\"\n",
    "\n",
    "    if set_random:\n",
    "        set_random_seed()\n",
    "\n",
    "    test_samples, ground_truth = collect_samples_to_predict(\n",
    "        datamodule, num_samples=num_samples\n",
    "    )\n",
    "    predictions = make_predictions(\n",
    "        lightning_model=lightning_model, test_samples=test_samples\n",
    "    )\n",
    "\n",
    "    plotting(test_samples, predictions, ground_truth, lightning_model, normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_vs_truth(\n",
    "    lightning_model=lightning_model,\n",
    "    datamodule=datamodule,\n",
    "    set_random=True,\n",
    "    normalized=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the modeL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(\n",
    "#     model=model_v1,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     num_epochs=NUM_EPOCHS,\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly collect 10 plane and 10 no-plane images\n",
    "\n",
    "file_folder = \"planesnet/planesnet\"\n",
    "\n",
    "num_images = 6\n",
    "list_of_planes = []\n",
    "list_of_no_planes = []\n",
    "\n",
    "list_of_files = os.listdir(file_folder)\n",
    "shuffled_file_folder = random.sample(list_of_files, len(list_of_files))\n",
    "\n",
    "for filename in shuffled_file_folder:\n",
    "\n",
    "    if len(list_of_planes) < num_images and filename[0] == \"1\":\n",
    "        list_of_planes.append(filename)\n",
    "\n",
    "    if len(list_of_no_planes) <= num_images and filename[0] == \"0\":\n",
    "        list_of_no_planes.append(filename)\n",
    "\n",
    "list_of_planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### modify this\n",
    "\n",
    "\n",
    "# img_path = \"600225-670x447-1.jpg\" # politician\n",
    "\n",
    "# img_path = list_of_planes[3]\n",
    "\n",
    "\n",
    "def plot_grad_cam_images(\n",
    "    lightning_model: L.LightningModule,\n",
    "    file_name: str,\n",
    "    file_folder: str = \"planesnet/planesnet\",\n",
    ") -> None:\n",
    "\n",
    "    img_path = file_folder + \"/\" + file_name\n",
    "    # Load and preprocess the image\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = img.resize((20, 20))\n",
    "    img = np.array(img)\n",
    "    img_float_np = np.float32(img) / 255.0\n",
    "    input_tensor = torch.from_numpy(img.transpose(2, 0, 1))\n",
    "    input_tensor = input_tensor.type(torch.float32).unsqueeze(dim=0)\n",
    "\n",
    "    # Model evaluation\n",
    "    lightning_model.eval()\n",
    "    with torch.inference_mode():\n",
    "        outputs = lightning_model(input_tensor)\n",
    "        y_pred_label = torch.argmax(outputs, dim=1)\n",
    "    y_pred_label = y_pred_label.cpu().detach().item()\n",
    "\n",
    "    # Grad-CAM setup\n",
    "    target_layer = [lightning_model.model.layers[6]]\n",
    "    cam = GradCAM(model=lightning_model, target_layers=target_layer)\n",
    "    target_category = 1\n",
    "    target_label = [ClassifierOutputTarget(target_category)]\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=target_label)\n",
    "    grayscale_cam_ = grayscale_cam[0, :]\n",
    "    cam_image = show_cam_on_image(img_float_np, grayscale_cam_, use_rgb=True)\n",
    "\n",
    "    # Determine true and predicted labels\n",
    "    y_true = \"Plane\" if file_name[0] == \"1\" else \"No Plane\"\n",
    "    y_pred = \"Plane\" if y_pred_label == 1 else \"No Plane\"\n",
    "    title_text = f\"Prediction: {y_pred} | Truth: {y_true}\"\n",
    "    title_color = \"g\" if y_true == y_pred else \"r\"\n",
    "\n",
    "    # Plotting\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 0.05])\n",
    "\n",
    "    plt.suptitle(title_text, fontsize=15, c=title_color)\n",
    "\n",
    "    # Grad-CAM overlay image\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(cam_image)\n",
    "    ax1.set_title(f\"(Grad-CAM)\")\n",
    "    ax1.axis(\"on\")\n",
    "\n",
    "    # Original image\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.imshow(img)\n",
    "    ax2.set_title(f\"(Original)\")\n",
    "    ax2.axis(\"on\")\n",
    "\n",
    "    # Colorbar\n",
    "    cbar_ax = fig.add_subplot(gs[0, 2])\n",
    "    cmap = plt.cm.inferno\n",
    "    norm = plt.Normalize(vmin=grayscale_cam.min(), vmax=grayscale_cam.max())\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    cbar = plt.colorbar(sm, cax=cbar_ax, orientation=\"vertical\")\n",
    "    cbar.set_label(\"Activation Strength\")\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for filename in list_of_planes:\n",
    "    plot_grad_cam_images(lightning_model=lightning_model, file_name=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in list_of_no_planes:\n",
    "    plot_grad_cam_images(lightning_model=lightning_model, file_name=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify planes on scene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_on_scene(lighting_model: L.LightningModule, img_boxes: np.ndarray):\n",
    "    input_transposed = img_boxes.transpose(0, 3, 1, 2)\n",
    "    input_tensor = torch.from_numpy(input_transposed).type(torch.float32)\n",
    "    output_logits = lighting_model(input_tensor)\n",
    "    predictions = torch.argmax(output_logits, dim=1)\n",
    "    return predictions.cpu().numpy()\n",
    "\n",
    "\n",
    "def process_scene(image_name, lightning_model, stride=5, img_folder=\"scenes/scenes\"):\n",
    "    img_input_size = 20\n",
    "    image_path = os.path.join(img_folder, image_name)\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "    ax.imshow(img)\n",
    "\n",
    "    patches_list = []\n",
    "    coords_list = []\n",
    "\n",
    "    for h in range(0, height - img_input_size, stride):\n",
    "        for w in range(0, width - img_input_size, stride):\n",
    "            img_box = img[h : h + img_input_size, w : w + img_input_size]\n",
    "            patches_list.append(img_box)\n",
    "            coords_list.append((w, h))\n",
    "\n",
    "    img_boxes = np.array(patches_list)\n",
    "    predictions = make_predictions_on_scene(lightning_model, img_boxes)\n",
    "\n",
    "    for (w, h), prediction in zip(coords_list, predictions):\n",
    "        if prediction == 1:\n",
    "            ax.add_patch(\n",
    "                matplotlib.patches.Rectangle(\n",
    "                    (w, h),\n",
    "                    img_input_size,\n",
    "                    img_input_size,\n",
    "                    edgecolor=\"r\",\n",
    "                    facecolor=\"none\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "    plt.savefig(f\"predict_from_scene_plots/predicted_{image_name}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "img_path = \"scene_2.png\"\n",
    "process_scene(img_path, lightning_model, stride=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_folder = \"scenes/scenes\"\n",
    "for img_name in os.listdir(scenes_folder):\n",
    "\n",
    "    process_scene(img_name, lightning_model, stride=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with images from other dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"scenes/extras\")\n",
    "\n",
    "scenes_folder = \"scenes/extras\"\n",
    "for img_name in os.listdir(scenes_folder):\n",
    "\n",
    "    process_scene(img_name, lightning_model, stride=5, img_folder=scenes_folder)\n",
    "\n",
    "# process_scene(img_name, model_v1, stride=5, img_input_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to train and evaluate pretrained models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(watermark(packages=\"torch, lightning\", python=True))\n",
    "print(device)\n",
    "RANDOM_SEED = 123\n",
    "INPUT_SIZE = 20\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "NUM_EPOCHS = 47\n",
    "LEARNING_RATE = 0.05\n",
    "DEVICE = device\n",
    "\n",
    "L.seed_everything(RANDOM_SEED)\n",
    "\n",
    "datamodule = PlanesLightningDataModule(\n",
    "    dataframe=image_data,\n",
    "    normalized=True,  # [0, 1]\n",
    "    apply_aug=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    data_transforms=None,\n",
    "    test_size=TEST_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_pretrained(\n",
    "    pytorch_model: torch.nn.Module,\n",
    "    datamodule: L.LightningDataModule,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    input_size=INPUT_SIZE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "):\n",
    "\n",
    "    model_name = pytorch_model.__class__.__name__\n",
    "    ### train\n",
    "    lightning_model = PlanesLightningModule(\n",
    "        pytorch_model, learning_rate=learning_rate, input_size=input_size\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        TQDMProgressBar(refresh_rate=20),\n",
    "        ModelSummary(max_depth=3),\n",
    "        # RichProgressBar(leave=True),\n",
    "        # EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5),\n",
    "    ]\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        # fast_dev_run=2,\n",
    "        max_epochs=num_epochs,\n",
    "        accelerator=\"mps\",\n",
    "        devices=\"auto\",\n",
    "        logger=CSVLogger(save_dir=\"logs\", name=f\"my_lightning_{model_name}\"),\n",
    "        precision=\"16-mixed\",\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        model=lightning_model,\n",
    "        # train_dataloaders=None,\n",
    "        # val_dataloaders=None,\n",
    "        datamodule=datamodule,\n",
    "    )\n",
    "\n",
    "    ### training results\n",
    "    plot_loss_and_acc(trainer.logger.log_dir)\n",
    "\n",
    "    ### evaluate\n",
    "    avg_test_loss, test_loss_per_batch, y_true_labels, y_predictions = (\n",
    "        evaluate_the_lightning_model(\n",
    "            lightning_model=lightning_model,\n",
    "            datamodule=datamodule,\n",
    "        )\n",
    "    )\n",
    "    ### confusion_matrix\n",
    "    get_confusion_matrix(y_true=y_true_labels, y_pred=y_predictions)\n",
    "\n",
    "    ### plot test loss per batch\n",
    "    plot_test_loss_per_batch(\n",
    "        test_loss_per_batch,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        lr=LEARNING_RATE,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "    )\n",
    "\n",
    "    ### plot pred vs truth\n",
    "    plot_pred_vs_truth(\n",
    "        lightning_model=lightning_model,\n",
    "        datamodule=datamodule,\n",
    "        set_random=True,\n",
    "        normalized=True,\n",
    "    )\n",
    "\n",
    "\n",
    "### usage\n",
    "# train_and_evaluate_pretrained(\n",
    "#     pytorch_model=pytorch_model,\n",
    "#     datamodule=datamodule,\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "#     input_size=INPUT_SIZE,\n",
    "#     num_epochs=NUM_EPOCHS,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Resnet18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "resnet18_pytorch = torch.hub.load(\n",
    "    \"pytorch/vision\", \"resnet18\", weights=\"ResNet18_Weights.DEFAULT\"\n",
    ")\n",
    "\n",
    "for param in resnet18_pytorch.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "summary(resnet18_pytorch, input_size=[1, 3, 20, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = resnet18_pytorch.fc.in_features\n",
    "resnet18_pytorch.fc = nn.Linear(in_features, out_features=2)\n",
    "\n",
    "summary(resnet18_pytorch, input_size=[1, 3, 20, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## usage\n",
    "train_and_evaluate_pretrained(\n",
    "    pytorch_model=resnet18_pytorch,\n",
    "    datamodule=datamodule,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    input_size=INPUT_SIZE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss_and_acc(trainer.logger.log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_loss, test_loss_per_batch, y_true_labels, y_predictions = (\n",
    "    evaluate_the_lightning_model(\n",
    "        lightning_model=lightning_model,\n",
    "        datamodule=datamodule,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_preds = []\n",
    "# incorrect_preds = []\n",
    "\n",
    "\n",
    "# type(y_true_labels)\n",
    "# print(y_true_labels[0] == y_predictions[0])\n",
    "\n",
    "# for i in range(len(y_true_labels)):\n",
    "#     if y_predictions[i] == y_true_labels[i]:\n",
    "#         correct_preds.append(i)\n",
    "#     else:\n",
    "#         incorrect_preds.append(i)\n",
    "\n",
    "# print(f\"Correct predictions: {len(correct_preds)}\")\n",
    "# print(f\"Incorrect predictions: {len(incorrect_preds)}\")\n",
    "# print(\n",
    "#     f\"accuracy: {len(correct_preds)/(len(correct_preds) + len(incorrect_preds)) * 100:.2f}%\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_confusion_matrix(y_true=y_true_labels, y_pred=y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_test_loss_per_batch(\n",
    "#     test_loss_per_batch, batch_size=BATCH_SIZE, lr=LEARNING_RATE, num_epochs=NUM_EPOCHS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_pred_vs_truth(\n",
    "#     lightning_model=lightning_model,\n",
    "#     datamodule=datamodule,\n",
    "#     set_random=True,\n",
    "#     normalized=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. resnet50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model = torch.hub.load(\n",
    "    \"pytorch/vision\", \"resnet50\", weights=\"ResNet50_Weights.IMAGENET1K_V1\"\n",
    ")\n",
    "\n",
    "for param in resnet50_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "summary(resnet50_model, input_size=[1, 3, 20, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = resnet50_model.fc.in_features\n",
    "resnet50_model.fc = nn.Linear(in_features, out_features=2)\n",
    "\n",
    "summary(resnet50_model, input_size=[1, 3, 20, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## usage\n",
    "train_and_evaluate_pretrained(\n",
    "    pytorch_model=resnet50_model,\n",
    "    datamodule=datamodule,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    input_size=INPUT_SIZE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    ")\n",
    "\n",
    "# print(watermark(packages=\"torch, lightning\", python=True))\n",
    "# print(device)\n",
    "\n",
    "# RANDOM_SEED = 123\n",
    "# INPUT_SIZE = 20\n",
    "# BATCH_SIZE = 64\n",
    "# TEST_SIZE = 0.2\n",
    "\n",
    "# NUM_EPOCHS = 20\n",
    "# LEARNING_RATE = 0.05\n",
    "\n",
    "# L.seed_everything(RANDOM_SEED)\n",
    "\n",
    "# datamodule = PlanesLightningDataModule(\n",
    "#     dataframe=image_data,\n",
    "#     normalized=True,  # [0, 1]\n",
    "#     apply_aug=True,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     data_transforms=None,\n",
    "#     test_size=TEST_SIZE,\n",
    "# )\n",
    "\n",
    "\n",
    "# lightning_model = PlanesLightningModule(\n",
    "#     resnet50_model, learning_rate=LEARNING_RATE, input_size=INPUT_SIZE\n",
    "# )  # lr is key\n",
    "\n",
    "# callbacks = [\n",
    "#     TQDMProgressBar(refresh_rate=20),\n",
    "#     ModelSummary(max_depth=3),\n",
    "#     # RichProgressBar(leave=True),\n",
    "#     EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5),\n",
    "# ]\n",
    "\n",
    "# trainer = L.Trainer(\n",
    "#     # fast_dev_run=2,\n",
    "#     max_epochs=NUM_EPOCHS,\n",
    "#     accelerator=\"mps\",\n",
    "#     devices=\"auto\",\n",
    "#     logger=CSVLogger(save_dir=\"logs\", name=\"my_lightning_model\"),\n",
    "#     precision=\"16-mixed\",\n",
    "#     callbacks=callbacks,\n",
    "# )\n",
    "\n",
    "# train_time_start = timer()\n",
    "# trainer.fit(\n",
    "#     model=lightning_model,\n",
    "#     # train_dataloaders=None,\n",
    "#     # val_dataloaders=None,\n",
    "#     datamodule=datamodule,\n",
    "# )\n",
    "# train_time_end = timer()\n",
    "# total_train_time_model_0 = print_train_time(\n",
    "#     start=train_time_start,\n",
    "#     end=train_time_end,\n",
    "#     device=device,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss_and_acc(trainer.logger.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_test_loss, test_loss_per_batch, y_true_labels, y_predictions = (\n",
    "#     evaluate_the_lightning_model(\n",
    "#         lightning_model=lightning_model,\n",
    "#         datamodule=datamodule,\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_preds = []\n",
    "# incorrect_preds = []\n",
    "\n",
    "\n",
    "# type(y_true_labels)\n",
    "# print(y_true_labels[0] == y_predictions[0])\n",
    "\n",
    "# for i in range(len(y_true_labels)):\n",
    "#     if y_predictions[i] == y_true_labels[i]:\n",
    "#         correct_preds.append(i)\n",
    "#     else:\n",
    "#         incorrect_preds.append(i)\n",
    "\n",
    "# print(f\"Correct predictions: {len(correct_preds)}\")\n",
    "# print(f\"Incorrect predictions: {len(incorrect_preds)}\")\n",
    "# print(\n",
    "#     f\"accuracy: {len(correct_preds)/(len(correct_preds) + len(incorrect_preds)) * 100:.2f}%\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_confusion_matrix(y_true=y_true_labels, y_pred=y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_test_loss_per_batch(\n",
    "#     test_loss_per_batch, batch_size=BATCH_SIZE, lr=LEARNING_RATE, num_epochs=NUM_EPOCHS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_pred_vs_truth(\n",
    "#     lightning_model=lightning_model,\n",
    "#     datamodule=datamodule,\n",
    "#     set_random=True,\n",
    "#     normalized=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNetV2-S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_v2_s = torchvision.models.efficientnet_v2_s(weights=\"IMAGENET1K_V1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(\n",
    "    model=efficientnet_v2_s,\n",
    "    input_size=(1, 3, 20, 20),  # make sure this is \"input_size\", not \"input_shape\"\n",
    "    # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_v2_s = torchvision.models.efficientnet_v2_s(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "for param in efficientnet_v2_s.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the manual seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "\n",
    "# Recreate the classifier layer and seed it to the target device\n",
    "efficientnet_v2_s.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(\n",
    "        in_features=1280,\n",
    "        out_features=2,  # same number of output units as our number of classes\n",
    "        bias=True,\n",
    "    ),\n",
    ").to(device)\n",
    "\n",
    "\n",
    "summary(\n",
    "    efficientnet_v2_s,\n",
    "    input_size=(1, 3, 224, 224),\n",
    "    verbose=0,\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(watermark(packages=\"torch, lightning\", python=True))\n",
    "print(device)\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "INPUT_SIZE = 20\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "NUM_EPOCHS = 47\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "L.seed_everything(RANDOM_SEED)\n",
    "\n",
    "datamodule = PlanesLightningDataModule(\n",
    "    dataframe=image_data,\n",
    "    normalized=True,  # [0, 1]\n",
    "    apply_aug=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    data_transforms=None,\n",
    "    test_size=TEST_SIZE,\n",
    ")\n",
    "\n",
    "train_and_evaluate_pretrained(\n",
    "    pytorch_model=efficientnet_v2_s,\n",
    "    datamodule=datamodule,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    input_size=INPUT_SIZE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    ")\n",
    "\n",
    "\n",
    "# lightning_model = PlanesLightningModule(\n",
    "#     efficientnet_v2_s, learning_rate=LEARNING_RATE, input_size=INPUT_SIZE\n",
    "# )  # lr is key\n",
    "\n",
    "# callbacks = [\n",
    "#     TQDMProgressBar(refresh_rate=20),\n",
    "#     ModelSummary(max_depth=3),\n",
    "#     # RichProgressBar(leave=True),\n",
    "#     EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5),\n",
    "# ]\n",
    "\n",
    "# trainer = L.Trainer(\n",
    "#     # fast_dev_run=2,\n",
    "#     max_epochs=NUM_EPOCHS,\n",
    "#     accelerator=\"mps\",\n",
    "#     devices=\"auto\",\n",
    "#     logger=CSVLogger(save_dir=\"logs\", name=\"my_lightning_model\"),\n",
    "#     precision=\"16-mixed\",\n",
    "#     callbacks=callbacks,\n",
    "# )\n",
    "\n",
    "# train_time_start = timer()\n",
    "# trainer.fit(\n",
    "#     model=lightning_model,\n",
    "#     # train_dataloaders=None,\n",
    "#     # val_dataloaders=None,\n",
    "#     datamodule=datamodule,\n",
    "# )\n",
    "# train_time_end = timer()\n",
    "# total_train_time_model_0 = print_train_time(\n",
    "#     start=train_time_start,\n",
    "#     end=train_time_end,\n",
    "#     device=device,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss_and_acc(trainer.logger.log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_test_loss, test_loss_per_batch, y_true_labels, y_predictions = (\n",
    "#     evaluate_the_lightning_model(\n",
    "#         lightning_model=lightning_model,\n",
    "#         datamodule=datamodule,\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_preds = []\n",
    "# incorrect_preds = []\n",
    "\n",
    "\n",
    "# type(y_true_labels)\n",
    "# print(y_true_labels[0] == y_predictions[0])\n",
    "\n",
    "# for i in range(len(y_true_labels)):\n",
    "#     if y_predictions[i] == y_true_labels[i]:\n",
    "#         correct_preds.append(i)\n",
    "#     else:\n",
    "#         incorrect_preds.append(i)\n",
    "\n",
    "# print(f\"Correct predictions: {len(correct_preds)}\")\n",
    "# print(f\"Incorrect predictions: {len(incorrect_preds)}\")\n",
    "# print(\n",
    "#     f\"accuracy: {len(correct_preds)/(len(correct_preds) + len(incorrect_preds)) * 100:.2f}%\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_confusion_matrix(y_true=y_true_labels, y_pred=y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_test_loss_per_batch(\n",
    "#     test_loss_per_batch, batch_size=BATCH_SIZE, lr=LEARNING_RATE, num_epochs=NUM_EPOCHS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_pred_vs_truth(\n",
    "#     lightning_model=lightning_model,\n",
    "#     datamodule=datamodule,\n",
    "#     set_random=True,\n",
    "#     normalized=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilenet_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2 = torchvision.models.mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "for param in mobilenet_v2.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "summary(\n",
    "    model=mobilenet_v2,\n",
    "    input_size=(1, 3, 20, 20),  # make sure this is \"input_size\", not \"input_shape\"\n",
    "    # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in mobilenet_v2.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "# Set the manual seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Recreate the classifier layer and seed it to the target device\n",
    "mobilenet_v2.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(\n",
    "        in_features=1280,\n",
    "        out_features=2,  # same number of output units as our number of classes\n",
    "        bias=True,\n",
    "    ),\n",
    ").to(device)\n",
    "\n",
    "summary(\n",
    "    mobilenet_v2,\n",
    "    input_size=(1, 3, 224, 224),\n",
    "    verbose=0,\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_pretrained(\n",
    "    pytorch_model=mobilenet_v2,\n",
    "    datamodule=datamodule,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    input_size=INPUT_SIZE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [NO] densenet121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet121 = torchvision.models.densenet121(weights=\"IMAGENET1K_V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet121 = torchvision.models.densenet121(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# for param in densenet121.features.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "\n",
    "# # Set the manual seeds\n",
    "# torch.manual_seed(42)\n",
    "# torch.cuda.manual_seed(42)\n",
    "\n",
    "# # Recreate the classifier layer and seed it to the target device\n",
    "# densenet121.classifier = torch.nn.Sequential(\n",
    "#     torch.nn.Dropout(p=0.2, inplace=True),\n",
    "#     torch.nn.Linear(\n",
    "#         in_features=1280,\n",
    "#         out_features=2,  # same number of output units as our number of classes\n",
    "#         bias=True,\n",
    "#     ),\n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate_pretrained(\n",
    "#     pytorch_model=densenet121,\n",
    "#     datamodule=datamodule,\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "#     input_size=INPUT_SIZE,\n",
    "#     num_epochs=NUM_EPOCHS,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [NO] vit_b_16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vit_b_16 = torchvision.models.vit_b_16(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# for param in vit_b_16.encoder.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in vit_b_16.conv_proj.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Set the manual seeds\n",
    "# torch.manual_seed(42)\n",
    "# torch.cuda.manual_seed(42)\n",
    "\n",
    "# # Recreate the classifier layer and seed it to the target device\n",
    "# vit_b_16.heads = torch.nn.Sequential(\n",
    "#     torch.nn.Dropout(p=0.2, inplace=True),\n",
    "#     torch.nn.Linear(\n",
    "#         in_features=768,\n",
    "#         out_features=2,  # same number of output units as our number of classes\n",
    "#         bias=True,\n",
    "#     ),\n",
    "# ).to(device)\n",
    "\n",
    "# # train_and_evaluate_pretrained(\n",
    "# #     pytorch_model=vit_b_16,\n",
    "# #     datamodule=datamodule,\n",
    "# #     learning_rate=LEARNING_RATE,\n",
    "# #     input_size=INPUT_SIZE,\n",
    "# #     num_epochs=NUM_EPOCHS,\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
